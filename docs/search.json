[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nYuzhi Tao\n\n\nApr 23, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yuzhi Tao",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, more than 50,000 prior donors to a politically progressive nonprofit organization were randomly assigned to receive one of several fundraising letters via direct mail. The control group received a standard appeal for donations. The treatment group received one of several versions of a letter announcing a matching grant: either a 1:1, 2:1, or 3:1 match, meaning the donor’s contribution would be matched by $1, $2, or $3 for every $1 given, respectively. The letters also varied in the maximum size of the matching grant, which was either $25,000, $50,000, $100,000, or left unspecified.The letters also gave people a hint about how much to give, based on how much they gave before.\nThis design allows for analysis of how different aspects of a fundraising message affect donor behavior, specifically: - whether people donate at all - how much they give - whether larger matching ratios lead to higher engagement\nThe randomized design ensures that the causal effect of the message content can be estimated.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/index.html#introduction",
    "href": "blog/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the experiment, more than 50,000 prior donors to a politically progressive nonprofit organization were randomly assigned to receive one of several fundraising letters via direct mail. The control group received a standard appeal for donations. The treatment group received one of several versions of a letter announcing a matching grant: either a 1:1, 2:1, or 3:1 match, meaning the donor’s contribution would be matched by $1, $2, or $3 for every $1 given, respectively. The letters also varied in the maximum size of the matching grant, which was either $25,000, $50,000, $100,000, or left unspecified.The letters also gave people a hint about how much to give, based on how much they gave before.\nThis design allows for analysis of how different aspects of a fundraising message affect donor behavior, specifically: - whether people donate at all - how much they give - whether larger matching ratios lead to higher engagement\nThe randomized design ensures that the causal effect of the message content can be estimated.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/index.html#data",
    "href": "blog/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThis dataset includes donation behavior and treatment assignments from a large field experiment on charitable giving. It contains a rich set of variables covering match offers, donation history, demographics, and political/geographic characteristics.\n\n\n\n\n\n\nDataset Table\n\n\n\n\n\n\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\ndata\n\n# A tibble: 50,083 × 51\n   treatment control ratio    ratio2 ratio3 size    size25 size50 size100 sizeno\n       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl+lb&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl+l&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1         0       1 0 [Cont…      0      0 0 [Con…      0      0       0      0\n 2         0       1 0 [Cont…      0      0 0 [Con…      0      0       0      0\n 3         1       0 1             0      0 3 [$10…      0      0       1      0\n 4         1       0 1             0      0 4 [Uns…      0      0       0      1\n 5         1       0 1             0      0 2 [$50…      0      1       0      0\n 6         0       1 0 [Cont…      0      0 0 [Con…      0      0       0      0\n 7         1       0 1             0      0 1 [$25…      1      0       0      0\n 8         1       0 2             1      0 3 [$10…      0      0       1      0\n 9         1       0 2             1      0 4 [Uns…      0      0       0      1\n10         1       0 1             0      0 1 [$25…      1      0       0      0\n# ℹ 50,073 more rows\n# ℹ 41 more variables: ask &lt;dbl+lbl&gt;, askd1 &lt;dbl&gt;, askd2 &lt;dbl&gt;, askd3 &lt;dbl&gt;,\n#   ask1 &lt;dbl&gt;, ask2 &lt;dbl&gt;, ask3 &lt;dbl&gt;, amount &lt;dbl&gt;, gave &lt;dbl&gt;,\n#   amountchange &lt;dbl&gt;, hpa &lt;dbl&gt;, ltmedmra &lt;dbl&gt;, freq &lt;dbl&gt;, years &lt;dbl&gt;,\n#   year5 &lt;dbl&gt;, mrm2 &lt;dbl&gt;, dormant &lt;dbl&gt;, female &lt;dbl&gt;, couple &lt;dbl&gt;,\n#   state50one &lt;dbl&gt;, nonlit &lt;dbl&gt;, cases &lt;dbl&gt;, statecnt &lt;dbl&gt;,\n#   stateresponse &lt;dbl&gt;, stateresponset &lt;dbl&gt;, stateresponsec &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nBefore analyzing the effects of the treatment, it’s important to confirm that the treatment and control groups were similar to begin with. To do this, I test whether key baseline characteristics differ between the groups. This ensures that any observed outcomes can be confidently attributed to the treatment itself.\n\ntreated &lt;- filter(data, treatment == 1)\ncontrol &lt;- filter(data, treatment == 0)\n\nmean_treat &lt;- mean(treated$mrm2, na.rm = TRUE)\nmean_control &lt;- mean(control$mrm2, na.rm = TRUE)\n\nsd_treat &lt;- sd(treated$mrm2, na.rm = TRUE)\nsd_control &lt;- sd(control$mrm2, na.rm = TRUE)\n\nn_treat &lt;- sum(!is.na(treated$mrm2))\nn_control &lt;- sum(!is.na(control$mrm2))\n\nt_stat &lt;- (mean_treat - mean_control) / sqrt((sd_treat^2 / n_treat) + (sd_control^2 / n_control))\nt_stat\n\n[1] 0.1195316\n\nlm_balance &lt;- lm(mrm2 ~ treatment, data = data)\nsummary(lm_balance)\n\n\nCall:\nlm(formula = mrm2 ~ treatment, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.012  -9.012  -5.012   6.002 154.988 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.99814    0.09353 138.979   &lt;2e-16 ***\ntreatment    0.01369    0.11453   0.119    0.905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.08 on 50080 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  2.851e-07, Adjusted R-squared:  -1.968e-05 \nF-statistic: 0.01428 on 1 and 50080 DF,  p-value: 0.9049\n\n\nI compare the mrm2 between the treatment and control groups. Using both a manual t-test and a linear regression, I find no statistically significant difference. The t-statistic is 0.1195 and the regression p-value is 0.905. Both results show no statistically significant difference.\nThese findings match the results in Table 1 of the original paper, where the means for this variable are 13.012 for treatment group., and 12.998 for control group. Combined with similar standard deviations for both around 12.08, the small difference supports the idea that the groups are nearly identical on this pre-treatment characteristic.\nTable 1 is important because it shows that any later differences in giving behavior are likely due to the treatment, not pre-existing differences in the people themselves. That’s the power of random assignment, and allows this experiment to make strong causal claims.\n\n# female variable\n\nmean_female_treat &lt;- mean(treated$female, na.rm = TRUE)\nmean_female_control &lt;- mean(control$female, na.rm = TRUE)\n\nsd_female_treat &lt;- sd(treated$female, na.rm = TRUE)\nsd_female_control &lt;- sd(control$female, na.rm = TRUE)\n\nn_female_treat &lt;- sum(!is.na(treated$female))\nn_female_control &lt;- sum(!is.na(control$female))\n\nt_female &lt;- (mean_female_treat - mean_female_control) / \n  sqrt((sd_female_treat^2 / n_female_treat) + (sd_female_control^2 / n_female_control))\nt_female\n\n[1] -1.753513\n\nsummary(lm(female ~ treatment, data = data))\n\n\nCall:\nlm(formula = female ~ treatment, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.2827 -0.2752 -0.2752  0.7173  0.7248 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.282698   0.003504  80.688   &lt;2e-16 ***\ntreatment   -0.007547   0.004292  -1.758   0.0787 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4478 on 48970 degrees of freedom\n  (1111 observations deleted due to missingness)\nMultiple R-squared:  6.313e-05, Adjusted R-squared:  4.271e-05 \nF-statistic: 3.092 on 1 and 48970 DF,  p-value: 0.07869\n\n\nThen I tested the female variable. The t-statistic is -1.75 and the p-value from the regression is 0.079. This means we fail to reject the null hypothesis of no difference. In Table 1 of the paper, the proportion of females is 0.275 in treatment and 0.283 in control, so it is nearly identical to test results.\n\n# freq variable\n\nmean_freq_treat &lt;- mean(treated$freq, na.rm = TRUE)\nmean_freq_control &lt;- mean(control$freq, na.rm = TRUE)\n\nsd_freq_treat &lt;- sd(treated$freq, na.rm = TRUE)\nsd_freq_control &lt;- sd(control$freq, na.rm = TRUE)\n\nn_freq_treat &lt;- sum(!is.na(treated$freq))\nn_freq_control &lt;- sum(!is.na(control$freq))\n\nt_freq &lt;- (mean_freq_treat - mean_freq_control) / \n  sqrt((sd_freq_treat^2 / n_freq_treat) + (sd_freq_control^2 / n_freq_control))\nt_freq\n\n[1] -0.110845\n\nsummary(lm(freq ~ treatment, data = data))\n\n\nCall:\nlm(formula = freq ~ treatment, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n -8.035  -6.047  -4.035   1.953 209.965 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.04734    0.08821  91.231   &lt;2e-16 ***\ntreatment   -0.01198    0.10802  -0.111    0.912    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.39 on 50081 degrees of freedom\nMultiple R-squared:  2.455e-07, Adjusted R-squared:  -1.972e-05 \nF-statistic: 0.0123 on 1 and 50081 DF,  p-value: 0.9117\n\n\nI also tested freq, the number of prior donations, to assess whether this characteristic differed between treatment and control groups. The t-statistic is -0.11 and the regression p-value is 0.9117, indicating no statistically significant difference as well. These results match what we see in Table 1, where the average number of prior donations is 8.035 in treatment and 8.047 in control.\nThis further supports the idea that randomization was effective, and that any later differences in donation behavior are not due to differences in variables between the groups, just as shown in Table 1."
  },
  {
    "objectID": "blog/project1/index.html#experimental-results",
    "href": "blog/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\ndonate_rate &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(rate = mean(gave, na.rm = TRUE)) %&gt;%\n  mutate(treatment = ifelse(treatment == 1, \"Treatment\", \"Control\"))\n\nggplot(donate_rate, aes(x = treatment, y = rate, fill = treatment)) +\n  geom_bar(stat = \"identity\", width = 0.6) +\n  labs(title = \"Proportion of People Who Donated\",\n       x = \"Group\",\n       y = \"Donation Rate\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1))\n\n\n\n\n\n\n\n\n\n# t-test using formula\nmean_gave_treat &lt;- mean(treated$gave, na.rm = TRUE)\nmean_gave_control &lt;- mean(control$gave, na.rm = TRUE)\n\nsd_gave_treat &lt;- sd(treated$gave, na.rm = TRUE)\nsd_gave_control &lt;- sd(control$gave, na.rm = TRUE)\n\nn_gave_treat &lt;- sum(!is.na(treated$gave))\nn_gave_control &lt;- sum(!is.na(control$gave))\n\nt_stat_gave &lt;- (mean_gave_treat - mean_gave_control) / \n  sqrt((sd_gave_treat^2 / n_gave_treat) + (sd_gave_control^2 / n_gave_control))\nt_stat_gave\n\n[1] 3.209462\n\n# regression\nlm_gave &lt;- lm(gave ~ treatment, data = data)\nsummary(lm_gave)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\nAs we can see in the table, the average donation rate in the treatment group was about 2.2%, and 1.8% in the control group. This difference may sound small, but in the context of large-scale fundraising, it can mean a meaningful increase in revenue.\nThe t-test gave a t-statistic of 3.209462, and the linear regression returned a p-value of 0.0019. These results show a statistically significant increase in donation likelihood for those who received the matching offer.\nEven though the percentage difference is small, it matters in large-scale fundraising. These results support the paper’s main point that even small tweaks in message framing, like offering a match, can make a meaningful difference in behavior.\nAfter examining donation amounts among those who gave, I return to the broader question: does simply offering a match influence whether people donate at all? This is the central behavioral claim in the study, and it is where the strongest treatment effects are observed.\nTo answer this, I first compare donation rates between the treatment and control groups using a t-test and regression. I then estimate a probit model and calculate marginal effects to directly replicate the results shown in Table 3, Column 1 of the original paper.\n\nlibrary(margins)\n\nWarning: package 'margins' was built under R version 4.3.3\n\n# Probit model\nprobit_model &lt;- glm(gave ~ treatment, data = data, family = binomial(link = \"probit\"))\n\n# Marginal effects\nmargins_model &lt;- margins(probit_model)\nsummary(margins_model)\n\n    factor    AME     SE      z      p  lower  upper\n treatment 0.0043 0.0014 3.1044 0.0019 0.0016 0.0070\n\n\nThe estimated effect was 0.0043, meaning that a matching offer increases the likelihood of donating by about 0.43 percentage points, which is nearly identical to the 0.004 reported in Table 3 of the original study.\nThis confirms the earlier conclusion. While the increase in giving is small in absolute terms, it is statistically reliable and meaningful in a large-scale fundraising context. The matching offer acts as a subtle behavioral nudge, that encourage action from donors who may otherwise remain passive.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Subset data to just treated people with a match offer\nmatch_data &lt;- data %&gt;% filter(treatment == 1)\n\n# Subset into 3 groups by match ratio\ngroup_1_1 &lt;- match_data %&gt;% filter(ratio == 1)\ngroup_2_1 &lt;- match_data %&gt;% filter(ratio == 2)\ngroup_3_1 &lt;- match_data %&gt;% filter(ratio == 3)\n\n# Mean donation rates\nmean(group_1_1$gave, na.rm = TRUE)\n\n[1] 0.02074912\n\nmean(group_2_1$gave, na.rm = TRUE)\n\n[1] 0.02263338\n\nmean(group_3_1$gave, na.rm = TRUE)\n\n[1] 0.0227334\n\n# T-test: 2:1 vs 1:1\nt.test(group_2_1$gave, group_1_1$gave)\n\n\n    Welch Two Sample t-test\n\ndata:  group_2_1$gave and group_1_1$gave\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\n# T-test: 3:1 vs 2:1\nt.test(group_3_1$gave, group_2_1$gave)\n\n\n    Welch Two Sample t-test\n\ndata:  group_3_1$gave and group_2_1$gave\nt = 0.050116, df = 22261, p-value = 0.96\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.003811996  0.004012044\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02263338 \n\n\nI tested whether larger match ratios (2:1 and 3:1) were more effective than the 1:1 match at encouraging donations. The average donation rates were slightly higher in the higher match groups, showing: - 1:1 → 2.07% - 2:1 → 2.26% - 3:1 → 2.27%\nHowever, the t-tests show that these small increases are not statistically significant: - 2:1 vs 1:1: p = 0.33 - 3:1 vs 2:1: p = 0.96\nThese results are consistent with the authors’ interpretation in the paper. While matching offers increase giving overall, larger match ratios do not provide an additional boost. So although donors respond positively to the idea of a match, they don’t seem to care much about the size of the match that any match is enough to increase motivation.\n\n# Create ratio1 dummy: 1 if ratio == 1, else 0\ndata$ratio1 &lt;- ifelse(data$ratio == 1, 1, 0)\n\n# Only include treated group (people who received any match offer)\nmatch_only &lt;- filter(data, treatment == 1)\n\n# Run regression on 3 dummy variables: ratio1, ratio2, ratio3\nlm_ratio &lt;- lm(gave ~ ratio1 + ratio2 + ratio3, data = match_only)\nsummary(lm_ratio)\n\n\nCall:\nlm(formula = gave ~ ratio1 + ratio2 + ratio3, data = match_only)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02273 -0.02263 -0.02075  0.97925 \n\nCoefficients: (1 not defined because of singularities)\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.022733   0.001392  16.335   &lt;2e-16 ***\nratio1      -0.001984   0.001968  -1.008    0.313    \nratio2      -0.000100   0.001968  -0.051    0.959    \nratio3             NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1468 on 33393 degrees of freedom\nMultiple R-squared:  3.865e-05, Adjusted R-squared:  -2.124e-05 \nF-statistic: 0.6454 on 2 and 33393 DF,  p-value: 0.5245\n\n\nIn the regression output, the coefficient for ratio1 (1:1 match) is -0.002 and not statistically significant (p = 0.313), and the coefficient for ratio2 (2:1 match) is even smaller at -0.0001, with a p-value of 0.959. The variable ratio3 (3:1) was dropped due to perfect multicollinearity, which is expected since only two indicators are needed to define a three-level categorical variable.\nThe overall regression has an extremely low R-squared and a p-value of 0.52, confirming that differences in match size do not meaningfully explain variation in donation behavior. These results reinforce the key takeaway in the origional paper, that the presence of a match offer matters more than how large the match is.\n\nmean_1_1 &lt;- mean(group_1_1$gave, na.rm = TRUE)\nmean_2_1 &lt;- mean(group_2_1$gave, na.rm = TRUE)\nmean_3_1 &lt;- mean(group_3_1$gave, na.rm = TRUE)\n\ndiff_2_1_vs_1_1 &lt;- mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 &lt;- mean_3_1 - mean_2_1\n\ndiff_2_1_vs_1_1\n\n[1] 0.001884251\n\ndiff_3_1_vs_2_1\n\n[1] 0.000100024\n\n\nThe differences in donation response rates between match ratios were assessed using both raw data and regression estimates. From the raw data, the difference between the 2:1 and 1:1 match ratios was about 0.19%, and between 3:1 and 2:1 was just 0.01%. Using the fitted coefficients from the regression, I got identical results that the size of the match ratio has very little impact on the likelihood of giving.\nThese findings reinforce the main takeaway from the earlier analysis and the original paper. While offering a match increases donations, increasing the match ratio beyond 1:1 does not lead to meaningful gains. Donors appear to be influenced by the presence of a match itself but not its size.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Compare average donation amount (includes 0s for non-donors)\nmean_amount_treat &lt;- mean(treated$amount, na.rm = TRUE)\nmean_amount_control &lt;- mean(control$amount, na.rm = TRUE)\nmean_amount_treat\n\n[1] 0.9668733\n\nmean_amount_control\n\n[1] 0.8132678\n\n# T-test\nt.test(treated$amount, control$amount)\n\n\n    Welch Two Sample t-test\n\ndata:  treated$amount and control$amount\nt = 1.9183, df = 36216, p-value = 0.05509\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.003344493  0.310555423\nsample estimates:\nmean of x mean of y \n0.9668733 0.8132678 \n\n# Regression: amount ~ treatment\nlm_amount &lt;- lm(amount ~ treatment, data = data)\nsummary(lm_amount)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\nThe average donation amount was $0.97 in the treatment group and $0.81 in the control group, which results a modest difference. Statistical testing indicates that this difference is marginally significant, with p-values slightly above the conventional 5% threshold that 0.055 for the t-test and 0.063 for the regression.\nThese findings suggest that matching donation offers may not only encourage more people to give but also lead to slightly higher donation amounts on average. Although the effect is not strong in statistical terms, it is directionally consistent with the hypothesis that perceived impact increases generosity. In large-scale fundraising, even small increases in average gift size can contribute meaningfully to overall campaign success.\nAfter examining the effect of the matching offer on donation amounts across the full sample, the next step is to focus only on individuals who actually donated. This conditional analysis helps answer a more specific question: Does the treatment affect how much people give, once they’ve already decided to donate?\n\n# Filter to only include donors (positive donation amount)\ndonors_only &lt;- filter(data, gave == 1)\n\n# Regression: amount ~ treatment, among donors only\nlm_donor_amount &lt;- lm(amount ~ treatment, data = donors_only)\nsummary(lm_donor_amount)\n\n\nCall:\nlm(formula = amount ~ treatment, data = donors_only)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\nAmong donors, the average contribution was approximately $45.54, with no meaningful difference between treatment and control groups. The estimated effect of the matching offer was about –$1.67, and this difference is not statistically significant with a p-value of 0.56. This implies that the match offer did not influence the amount given giving the condition on donating.\nBecause treatment was randomly assigned, the regression coefficient still has a causal interpretation. However, the evidence here suggests that matching offers primarily affect the likelihood of giving, rather than how much is given once that decision is made.\nTo better understand how donation behavior differs between groups, I visualize the distribution of donation amounts among donors only. The red dashed line in each histogram represents the average donation for that group.\n\ndonors &lt;- filter(data, gave == 1)\n\nmean_treat &lt;- mean(donors$amount[donors$treatment == 1], na.rm = TRUE)\nmean_control &lt;- mean(donors$amount[donors$treatment == 0], na.rm = TRUE)\n\n# Plot for treatment group\nggplot(filter(donors, treatment == 1), aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", color = \"white\") +\n  geom_vline(xintercept = mean_treat, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Treatment Group: Donation Amounts\",\n       x = \"Donation Amount\",\n       y = \"Number of Donors\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n# Plot for control group\nggplot(filter(donors, treatment == 0), aes(x = amount)) +\n  geom_histogram(binwidth = 5, fill = \"lightgray\", color = \"white\") +\n  geom_vline(xintercept = mean_control, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Control Group: Donation Amounts\",\n       x = \"Donation Amount\",\n       y = \"Number of Donors\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nVisually, both groups display a similar pattern: most donations fall below $100, with a long right tail of higher-value contributions. The treatment group shows a slightly higher concentration around the mean, but the overall shape of the distribution is nearly identical.\nThe average donation in the treatment group appears modestly higher, but this visual evidence supports the regression results: once someone decides to give, the presence of a matching offer does not lead them to donate significantly more. This reinforces the earlier takeaway that the matching incentive affects the decision to give, rather than the amount given."
  },
  {
    "objectID": "blog/project1/index.html#simulation-experiment",
    "href": "blog/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo help build intuition for the reliability of statistical estimates, I use a simulation to demonstrate the Law of Large Numbers (LLN). This exercise mimics running many repeated experiments and shows how, as the number of simulations increases, the average difference in donation rates between the treatment and control groups stabilizes near the true underlying value.\n\nset.seed(42)\n\n# Simulate 10,000 draws from control and treatment (Bernoulli trials)\ncontrol_sim &lt;- rbinom(10000, 1, 0.018)\ntreat_sim &lt;- rbinom(10000, 1, 0.022)\n\n# Difference at each iteration\ndiffs &lt;- treat_sim - control_sim\n\n# Cumulative average\ncum_avg &lt;- cumsum(diffs) / seq_along(diffs)\n\n# True difference in means\ntrue_diff &lt;- 0.022 - 0.018\n\n# Plot\nplot(cum_avg, type = \"l\", col = \"steelblue\", lwd = 2,\n     main = \"Law of Large Numbers: Cumulative Difference in Means\",\n     xlab = \"Number of Simulations\", ylab = \"Cumulative Average Difference\")\nabline(h = true_diff, col = \"red\", lty = 2, lwd = 2)\nlegend(\"topright\", legend = c(\"Cumulative Avg\", \"True Difference\"),\n       col = c(\"steelblue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\nThe plot above shows the cumulative average difference in donation rates between simulated treatment and control groups over 10,000 draws. Early in the simulation, the average fluctuates quite a bit that sometimes even swinging in the wrong direction. This is because it’s based on just a few observations. But as more simulated observations accumulate, the average stabilizes and gradually converges to the true difference of 0.004, shown as the red dashed line.\nThis is a direct illustration of the Law of Large Numbers: as sample size increases, the sample average becomes a more reliable estimate of the population parameter. In this context, it reassures us that with large enough samples, like in the real experiment, even small differences in giving behavior can be detected and trusted.\n\n\nCentral Limit Theorem\nWhile the Law of Large Numbers shows that averages stabilize with more data, the Central Limit Theorem (CLT) explains something equally important: when we take averages from many repeated samples, the distribution of those averages becomes approximately normal, even if the original data is not. The following simulations demonstrate this by repeatedly sampling average differences in donation rates between treatment and control groups at different sample sizes.\n\nset.seed(123)\n\n# Function to simulate sampling distribution of differences\nsimulate_diff_means &lt;- function(n, reps = 1000, p_control = 0.018, p_treatment = 0.022) {\n  replicate(reps, {\n    control &lt;- rbinom(n, 1, p_control)\n    treatment &lt;- rbinom(n, 1, p_treatment)\n    mean(treatment) - mean(control)\n  })\n}\n\nsizes &lt;- c(50, 200, 500, 1000)\n\n# Run simulation for each sample size\ndiffs_50 &lt;- simulate_diff_means(50)\ndiffs_200 &lt;- simulate_diff_means(200)\ndiffs_500 &lt;- simulate_diff_means(500)\ndiffs_1000 &lt;- simulate_diff_means(1000)\n\nplot_hist &lt;- function(diffs, n) {\n  hist(diffs, breaks = 30, col = \"lightblue\", border = \"white\",\n       main = paste(\"Sample Size =\", n),\n       xlab = \"Average Difference in Donation Rates\")\n  abline(v = mean(diffs), col = \"red\", lwd = 2, lty = 2)\n}\n\npar(mfrow = c(2, 2))  \nplot_hist(diffs_50, 50)\nplot_hist(diffs_200, 200)\nplot_hist(diffs_500, 500)\nplot_hist(diffs_1000, 1000)\n\n\n\n\n\n\n\npar(mfrow = c(1, 1)) \n\nEach panel in the figure above shows the distribution of average differences in donation rates between treatment and control groups across 1,000 simulated experiments. As the sample size increases from 50 to 1,000, the distribution becomes tighter and more symmetric, with a shape that closely resembles a normal distribution.\nMost importantly, we can observe that zero is not at the center of these distributions, especially for larger sample sizes. Instead, the center shifts toward the true average difference in donation rates of 0.004. This means that as we collect more data, the observed average is increasingly likely to reflect the true effect of treatment, and zero (no difference) lies in the tail.\nThis aligns with the real-world experiment: the treatment had a small but real effect on donation rates. The simulation confirms that if there were truly no effect, the sampling distribution would center on zero. But in our case, it clearly doesn’t.\n\n\nConclusion\nThis analysis replicates key results from Karlan and List (2007), showing that matching donation offers increase both the likelihood and total amount of charitable giving, though not necessarily the size of individual gifts once a donor decides to give. Through a combination of statistical modeling, visualization, and simulation, we confirmed the paper’s main findings and built intuition for why they hold, even when effect sizes are small. The evidence suggests that simple framing changes, like offering a match, can act as effective behavioral nudges, especially when applied at scale. From both a theoretical and practical perspective, this case demonstrates the power of combining randomized experimentation with statistical reasoning to inform smarter decision-making in marketing and fundraising."
  }
]